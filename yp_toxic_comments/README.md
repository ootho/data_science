#  Определение токсичных комментариев  
  
[Просмотр ноутбука](https://nbviewer.org/github/ootho/data_science/blob/main/yp_toxic_comments/toxic_comments.ipynb)  
  
## Цель и задачи проекта  
  
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
  
В нашем распоряжении набор данных с разметкой о токсичности правок. Необходимо обучить модель, которая будет классифицировать комментарии на позитивные и негативные. 
  
В ходе работы будем использовать классические модели, а также попробуем `toxic-BERT`.  
  
**Стек: python, pandas, sklearn, catboost, nltk, pytorch**
  
## Вывод  
  
`Toxic-BERT` из коробки, без дообучения, показал `f1 = 0.84`, тогда как из классических моделей лучший результат показала `LogisticRegression` с результатом на тестовой выборке `f1 = 0.80`.  Если нет строгих требований по времени то мы можем использовать `toxic-BERT`, в противном случае стоит выбрать `LogisticRegression`.
