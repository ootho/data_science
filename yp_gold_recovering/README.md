# Восстановление золота из руды  
  
[Просмотр ноутбука](https://nbviewer.org/github/ootho/data_science/blob/main/yp_gold_recovering/gold_recovering.ipynb)  

## Цель и задачи проекта

Модель должна предсказать коэффициент восстановления золота из золотосодержащей руды. Также модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками.  
  
**Технологический процесс**  
Когда добытая руда проходит первичную обработку, получается дроблёная смесь. Её отправляют на флотацию (обогащение) и двухэтапную очистку:  
1. Флотация  
Во флотационную установку подаётся смесь золотосодержащей руды. После обогащения получается черновой концентрат и «отвальные хвосты», то есть остатки продукта с низкой концентрацией ценных металлов.
На стабильность этого процесса влияет непостоянное и неоптимальное физико-химическое состояние флотационной пульпы (смеси твёрдых частиц и жидкости).  
2. Очистка   
Черновой концентрат проходит две очистки. На выходе получается финальный концентрат и новые отвальные хвосты.  
    
**Стек: python, pandas, numpy, matplotlib, seaborn, sklearn**
  
## Вывод:

На первом этапе были погдготовлены данные проекта, а именно:  
   1. Из обучающей выборки были удалены признаки отсутствующие в тестовой выборке  
   2. В тестовую выборку были добавлены соотетствующие целевые признаки  
   3. Построена матрица корреляции и удалены признаки с мультиколлинеарностью  
   4. Данные предобработаны для обучения модели

На втором этапе был проведён анализ данных по заранее определённым критериям, было выявлено, что:  
   1. Концентрация серебра снижается на каждом этапе производства, концентрация золота повышается, концентрация свинца повышается после первого этапа и не изменяется после второго.    
   2. Распределения размеров гранул сырья на обучающей и тестовой выборках отличаются не сильно. Различие не повлияет на качество модели.  
   3. Суммарная концентрация всех веществ на протяжении цикла увеличивается.  

На третьем этапе:  
   1. Были написаны формулы для рассчёта sMAPE и итогового sMAPE  
   2. Было обучено несколько моделей LinearRegression, DecisionTreeRegressor, RandomForestRegressor, ElasticNet и перебраны гиперпараметры для них с помощью gridSearchCV  
   3. Лучшая модель прошла тест на тестовой выборке с результатом итогового sMAPE = 8.58%  
   4. Лучшая модель RandomForestRegressor(max_depth=4, n_estimators=13)  
